{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torchattacks\n",
    "\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load adversarial examples from different sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    def recreate_folder(folder_path):\n",
    "        if os.path.exists(folder_path):\n",
    "            os.system(f\"rm -rf {folder_path}\")\n",
    "        os.system(f\"mkdir {folder_path}\")\n",
    "\n",
    "    recreate_folder(\"all_adv_images\")\n",
    "    recreate_folder(\"all_FGSM_adv_images\")\n",
    "    recreate_folder(\"all_MIFGSM_adv_images\")\n",
    "    recreate_folder(\"all_PGD_adv_images\")\n",
    "    cnt = 0\n",
    "    for folders in os.listdir():\n",
    "        if folders.split(\"_\")[0] == \"resnet110\":\n",
    "            os.chdir(f\"{folders}/adv_imgs\")\n",
    "            attack_type = folders.split(\"_\")[-1]\n",
    "            cnt += 1\n",
    "            for images in os.listdir():\n",
    "                os.system(f\"cp {images} ../../all_adv_images/{images.split(\".\")[0]}_{cnt}_{attack_type}.png\")\n",
    "                os.system(f\"cp {images} ../../all_{attack_type}_adv_images/{images.split(\".\")[0]}_{cnt}_{attack_type}.png\")\n",
    "            os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start from here !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"train_batch_size\": 64,\n",
    "    \"batch_size\": 1,\n",
    "    \"model_name\": \"resnet110_cifar100\",\n",
    "    \"data_filepath\": \"./cifar-100_eval\",\n",
    "    \"train_adv_imgs_filepath\": \"./all_PGD_adv_images\",\n",
    "    \"test_adv_imgs_filepath\": \"./all_MIFGSM_adv_images\",\n",
    "    \"epoch\": 2,\n",
    "    \"seeds\": 10901036,\n",
    "    \"learning_rate\": 0.001,\n",
    "}\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "model = ptcv_get_model(config[\"model_name\"], pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model with adversarial images (adversarial training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar_Adveresarial100(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        super(Cifar_Adveresarial100, self).__init__()\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.datasize = len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.datasize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_files = sorted([os.path.join(config[\"data_filepath\"],x) for x in os.listdir(config[\"data_filepath\"]) if x.endswith(\".png\")])\n",
    "train_adv_files = sorted([os.path.join(config[\"train_adv_imgs_filepath\"], x) for x in os.listdir(config[\"train_adv_imgs_filepath\"]) if x.endswith(\".png\")])\n",
    "test_adv_files = None\n",
    "\n",
    "train_size = int(0.7 * len(train_adv_files))\n",
    "val_size = int(0.15 * len(train_adv_files))\n",
    "test_size = len(train_adv_files) - train_size - val_size\n",
    "original_size = len(original_files)\n",
    "train_files, val_files, test_files = random_split(train_adv_files, [train_size, val_size, test_size])\n",
    "\n",
    "train_imgs = torch.stack([transforms.ToTensor()(Image.open(filename)) for filename in train_files])\n",
    "val_imgs = torch.stack([transforms.ToTensor()(Image.open(filename)) for filename in val_files])\n",
    "test_imgs = torch.stack([transforms.ToTensor()(Image.open(filename)) for filename in test_files])\n",
    "original_imgs = torch.stack([transforms.ToTensor()(Image.open(filename)) for filename in original_files])\n",
    "\n",
    "train_labels = torch.tensor([int(filename.split('/')[-1].split('_')[0]) for filename in train_files], dtype=torch.long)\n",
    "val_labels = torch.tensor([int(filename.split('/')[-1].split('_')[0]) for filename in val_files], dtype=torch.long)\n",
    "test_labels = torch.tensor([int(filename.split('/')[-1].split('_')[0]) for filename in test_files], dtype=torch.long)\n",
    "original_labels = torch.tensor([int(filename.split('/')[-1].split('_')[0]) for filename in original_files], dtype=torch.long)\n",
    "\n",
    "train_datasets  = Cifar_Adveresarial100(train_imgs, train_labels)\n",
    "val_datasets    = Cifar_Adveresarial100(val_imgs, val_labels)\n",
    "test_datasets   = Cifar_Adveresarial100(test_imgs, test_labels)\n",
    "original_datasets = Cifar_Adveresarial100(original_imgs, original_labels)\n",
    "\n",
    "train_loader    = DataLoader(train_datasets, batch_size=config['train_batch_size'], shuffle=True, pin_memory=True)\n",
    "val_loader      = DataLoader(val_datasets , batch_size=config['batch_size'], shuffle=False, pin_memory=True)\n",
    "test_loader     = DataLoader(test_datasets, batch_size=config['batch_size'], shuffle=False, pin_memory=True)\n",
    "original_loader = DataLoader(original_datasets, batch_size=config['batch_size'], shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_test_adv_files = sorted([os.path.join(config[\"test_adv_imgs_filepath\"], x) for x in os.listdir(config[\"test_adv_imgs_filepath\"]) if x.endswith(\".png\")])\n",
    "another_test_imgs = torch.stack([transforms.ToTensor()(Image.open(filename)) for filename in another_test_adv_files])\n",
    "another_test_labels = torch.tensor([int(filename.split('/')[-1].split('_')[0]) for filename in another_test_adv_files], dtype=torch.long)\n",
    "another_test_datasets   = Cifar_Adveresarial100(another_test_imgs, another_test_labels)\n",
    "another_test_loader     = DataLoader(test_datasets, batch_size=config['batch_size'], shuffle=False, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original        size: 500\n",
      "Training        size: 1400\n",
      "Validating      size: 300\n",
      "Testing         size: 300\n",
      "Another Testing size: 2000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original        size: {len(original_datasets)}\")\n",
    "print(f\"Training        size: {len(train_datasets)}\")\n",
    "print(f\"Validating      size: {len(val_datasets)}\")\n",
    "print(f\"Testing         size: {len(test_datasets)}\")\n",
    "print(f\"Another Testing size: {len(another_test_datasets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "def train(model, train_loader, val_loader, criteria, optimizer, config):\n",
    "    for epoch in range(config['epoch']):\n",
    "        model.train()\n",
    "        for idx, (data, label) in tqdm(enumerate(train_loader)):\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            output = model(data)\n",
    "            loss = criteria(output, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 5 == 0:\n",
    "                print(f\"Epoch: {epoch}, Iter: {idx}, Loss: {loss.item()}\")\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for idx, (data, label) in tqdm(enumerate(val_loader)):\n",
    "                data, label = data.to(device), label.to(device)\n",
    "                output = model(data)\n",
    "                loss = criteria(output, label)\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                total += label.size(0)\n",
    "                correct += (predicted == label).sum().item()\n",
    "            print(f\"Epoch: {epoch}, Val Acc: {correct / total}, Val Loss: {loss.item()}\")\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_loader, model, device, data_size):\n",
    "    model.eval() # Set your model to evaluation mode.\n",
    "    acc = 0\n",
    "    for img, label in tqdm(test_loader):\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        with torch.no_grad():                   \n",
    "            pred = model(img) \n",
    "            if label[0] == torch.argmax(pred):\n",
    "                acc += 1\n",
    "    return acc / data_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:05<00:00, 85.27it/s]\n",
      "100%|██████████| 300/300 [00:03<00:00, 82.46it/s]\n",
      "100%|██████████| 300/300 [00:03<00:00, 88.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarially trained on: ./all_PGD_adv_images\n",
      "\n",
      "Tested on: ./all_PGD_adv_images and ./all_MIFGSM_adv_images\n",
      "\n",
      "Before adversarial training:\n",
      "\tOriginal_accuracy\t: 0.808\n",
      "\tAdv_accuracy\t\t: 0.07333333333333333\n",
      "\tAnother_test_accuracy\t: 0.011\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iter: 0, Loss: 1.731886625289917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:06,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iter: 5, Loss: 0.8804437518119812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:11,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iter: 10, Loss: 1.0970066785812378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:16,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iter: 15, Loss: 0.5897827744483948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:21,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iter: 20, Loss: 0.30227771401405334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:22,  1.00s/it]\n",
      "300it [00:03, 86.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Val Acc: 0.5833333333333334, Val Loss: 0.01865450106561184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iter: 0, Loss: 0.10926094651222229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:05,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iter: 5, Loss: 0.22990518808364868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:10,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iter: 10, Loss: 0.10496317595243454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:16,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iter: 15, Loss: 0.04009705409407616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:21,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Iter: 20, Loss: 0.027064047753810883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:21,  1.00it/s]\n",
      "300it [00:03, 86.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Val Acc: 0.9833333333333333, Val Loss: 0.0035271355882287025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:03<00:00, 82.46it/s]\n",
      "100%|██████████| 500/500 [00:05<00:00, 87.82it/s]\n",
      "100%|██████████| 300/300 [00:03<00:00, 86.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adversarial training:\n",
      "\tOriginal_accuracy\t: 0.994\n",
      "\tAdv_accuracy\t: 0.9766666666666667\n",
      "\tAnother_test_accuracy\t: 0.1465\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "original_acc_before = predict(original_loader, model, device, original_size)\n",
    "attack_acc_before = predict(test_loader, model, device, test_size)\n",
    "another_test_acc_before = attack_acc_before\n",
    "if config[\"test_adv_imgs_filepath\"] != config[\"train_adv_imgs_filepath\"]:\n",
    "    another_test_acc_before = predict(another_test_loader, model, device, len(another_test_datasets))\n",
    "\n",
    "print(f\"Adversarially trained on: {config[\"train_adv_imgs_filepath\"]}\\n\")\n",
    "print(f\"Tested on: {config[\"train_adv_imgs_filepath\"]} and {config[\"test_adv_imgs_filepath\"]}\\n\")\n",
    "    \n",
    "\n",
    "print(f\"Before adversarial training:\\n\\tOriginal_accuracy\\t: {original_acc_before}\\n\\tAdv_accuracy\\t\\t: {attack_acc_before}\\n\\tAnother_test_accuracy\\t: {another_test_acc_before}\")\n",
    "print(\"\")\n",
    "\n",
    "train(model, train_loader, val_loader, criteria, optimizer, config)\n",
    "\n",
    "defense_acc_after = predict(test_loader, model, device, test_size)\n",
    "original_acc_after = predict(original_loader, model, device, original_size)\n",
    "another_test_acc_after = predict(another_test_loader, model, device, len(another_test_datasets))\n",
    "\n",
    "print(f\"After adversarial training:\\n\\tOriginal_accuracy\\t: {original_acc_after}\\n\\tAdv_accuracy\\t: {defense_acc_after}\\n\\tAnother_test_accuracy\\t: {another_test_acc_after}\")\n",
    "print(\"\")\n",
    "\n",
    "with open(\"defense_info.txt\", 'a') as f:\n",
    "    f.write(f\"Model: {config[\"model_name\"]}\\n\")\n",
    "    f.write(f\"Adversarially trained on: {config[\"train_adv_imgs_filepath\"]} with epochs = {config[\"epoch\"]}\\n\")\n",
    "    f.write(f\"Tested on: {config[\"train_adv_imgs_filepath\"]} and {config[\"test_adv_imgs_filepath\"]}\\n\")\n",
    "    f.write(f\"Before adversarial training:\\n\\tOriginal_accuracy\\t: {original_acc_before}\\n\\tAdv_accuracy\\t\\t: {attack_acc_before}\\n\\tAnother_test_accuracy\\t: {another_test_acc_before}\\n\")\n",
    "    f.write(f\"After adversarial training:\\n\\tOriginal_accuracy\\t: {original_acc_after}\\n\\tAdv_accuracy\\t\\t: {defense_acc_after}\\n\\tAnother_test_accuracy\\t: {another_test_acc_after}\\n\")\n",
    "    f.write(\"\\n---------------------------------------------\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spml_HW1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
